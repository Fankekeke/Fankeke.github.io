<!DOCTYPE html><html lang="zh"><head><meta name="generator" content="Hugo 0.51"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="HandheldFriendly" content="True"><meta name="viewport" content="initial-scale=1,width=device-width,minimum-scale=1,maximum-scale=1,user-scalable=no"><meta name="wap-font-scale" content="no"><meta name="360-site-verification" content="0903ba33c82867d1f7bd8831e32a7e34"><meta name="sogou_site_verification" content="E8uWFBcf4a"><meta name="author" content="Fan"><meta name="description" itemprop="description" content="Alili | 前端大爆炸! - WEB BANG! BANG!! BANG!!! 前端大爆炸,一个前端技术博客.想到哪,学到哪,写到哪. 本文资源来源互联网，仅供学习研究使用，版权归该资源的合法拥有者所有， Alili, 前端大爆炸, WEB BANG BANG BANG, web前端博客, 前端模块化, 前端工程化, 前端数据监控, 性能优化, 网页制作, 前端, js, html5, css"><meta name="keywords" content="Alili, 前端大爆炸, WEB BANG BANG BANG, web前端博客, 前端模块化, 前端工程化, 前端数据监控, 性能优化, 网页制作, 前端, js, html5, css, 踩坑小报告, 微前端, 树莓派, 前端开发, 区块链, 网络, Mongodb, Vue.js, Angular.js, node.js"><meta property="og:locale" content="en_US"><meta property="og:title" content="使用 OpenCV 进行高动态范围（HDR）成像"><meta property="og:image" content="https://alili.tech/images/logo2.png"><meta property="og:description" content="Alili | 前端大爆炸! - WEB BANG! BANG!! BANG!!! 前端大爆炸,一个前端技术博客.想到哪,学到哪,写到哪. 本文资源来源互联网，仅供学习研究使用，版权归该资源的合法拥有者所有， Alili, 前端大爆炸, WEB BANG BANG BANG, web前端博客, 前端模块化, 前端工程化, 前端数据监控, 性能优化, 网页制作, 前端, js, html5, css"><meta property="og:site_name" content="Alili"><title>使用 OpenCV 进行高动态范围（HDR）成像 | 前端大爆炸! - WEB BANG! BANG!! BANG!!!</title><link rel="shortcut icon" href="https://alili.tech/images/favicon.ico"><link rel="manifest" href="/manifest.json"><link rel="stylesheet" href="https://alili.tech/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="https://alili.tech/lib/justified-gallery/justifiedGallery.min.css"><link rel="stylesheet" href="https://alili.tech/css/style.css"><script src="https://alili.tech/lib/highlight.min.js"></script><script>hljs.initHighlightingOnLoad();</script><script src="https://alili.tech/lib/jquery/jquery.min.js"></script><script>document.addEventListener("error", function (e) {
			  var elem = e.target;
			  if (elem.tagName.toLowerCase() == 'img') {
				elem.style.display='none'
			  }
			}, true);</script><script type="application/ld+json">{
				"@context": "https://ziyuan.baidu.com/contexts/cambrian.jsonld",
				"@id": "https://alili.tech/archive/855c5353/",
				"appid": "1613049289050283", 
				"title": "使用 OpenCV 进行高动态范围（HDR）成像 | 前端大爆炸! - WEB BANG! BANG!! BANG!!!", 
				"images": [],
				"pubDate": "2018-10-18T00:00:00"
			}</script></head><body><div id="header-post"><a id="menu-icon" href="#"><i class="fa fa-bars fa-lg"></i></a> <a id="menu-icon-tablet" href="#"><i class="fa fa-bars fa-lg"></i></a> <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa fa-chevron-up fa-lg"></i></a> <span id="menu"><span id="nav"><ul><li><a href="/">Home</a></li><li><a href="/archive/">Archives</a></li><li><a href="/about/">About</a></li><li><a href="http://github.com/Fantasy9527" target="_blank">Github</a></li></ul></span><br><span id="actions"><ul><li><a class="icon" href="https://alili.tech/archive/b06c3a33/"><i class="fa fa-chevron-left" aria-hidden="true" onmouseover='$("#i-prev").toggle();' onmouseout='$("#i-prev").toggle();'></i></a></li><li><a class="icon" href="https://alili.tech/archive/192f9dbe/"><i class="fa fa-chevron-right" aria-hidden="true" onmouseover='$("#i-next").toggle();' onmouseout='$("#i-next").toggle();'></i></a></li><li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa fa-chevron-up" aria-hidden="true" onmouseover='$("#i-top").toggle();' onmouseout='$("#i-top").toggle();'></i></a></li><li><a class="icon" href="#"><i class="fa fa-share-alt" aria-hidden="true" onmouseover='$("#i-share").toggle();' onmouseout='$("#i-share").toggle();' onclick='$("#share").toggle();return false;'></i></a></li></ul><span id="i-prev" class="info" style="display:none;">Previous post</span> <span id="i-next" class="info" style="display:none;">Next post</span> <span id="i-top" class="info" style="display:none;">Back to top</span> <span id="i-share" class="info" style="display:none;">Share post</span></span><br><div id="share" style="display: none"><ul><li><a class="icon" href="http://v.t.sina.com.cn/share/share.php?u=https%3a%2f%2falili.tech%2farchive%2f855c5353%2f&text=%e4%bd%bf%e7%94%a8%20OpenCV%20%e8%bf%9b%e8%a1%8c%e9%ab%98%e5%8a%a8%e6%80%81%e8%8c%83%e5%9b%b4%ef%bc%88HDR%ef%bc%89%e6%88%90%e5%83%8f"><i class="fa fa-weibo" aria-hidden="true"></i></a></li><li><a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2falili.tech%2farchive%2f855c5353%2f"><i class="fa fa-facebook" aria-hidden="true"></i></a></li><li><a class="icon" href="https://twitter.com/share?url=https%3a%2f%2falili.tech%2farchive%2f855c5353%2f&text=%e4%bd%bf%e7%94%a8%20OpenCV%20%e8%bf%9b%e8%a1%8c%e9%ab%98%e5%8a%a8%e6%80%81%e8%8c%83%e5%9b%b4%ef%bc%88HDR%ef%bc%89%e6%88%90%e5%83%8f"><i class="fa fa-twitter" aria-hidden="true"></i></a></li><li><a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2falili.tech%2farchive%2f855c5353%2f&title=%e4%bd%bf%e7%94%a8%20OpenCV%20%e8%bf%9b%e8%a1%8c%e9%ab%98%e5%8a%a8%e6%80%81%e8%8c%83%e5%9b%b4%ef%bc%88HDR%ef%bc%89%e6%88%90%e5%83%8f"><i class="fa fa-linkedin" aria-hidden="true"></i></a></li><li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2falili.tech%2farchive%2f855c5353%2f&is_video=false&description=%e4%bd%bf%e7%94%a8%20OpenCV%20%e8%bf%9b%e8%a1%8c%e9%ab%98%e5%8a%a8%e6%80%81%e8%8c%83%e5%9b%b4%ef%bc%88HDR%ef%bc%89%e6%88%90%e5%83%8f"><i class="fa fa-pinterest" aria-hidden="true"></i></a></li><li><a class="icon" href="mailto:?subject=%e4%bd%bf%e7%94%a8%20OpenCV%20%e8%bf%9b%e8%a1%8c%e9%ab%98%e5%8a%a8%e6%80%81%e8%8c%83%e5%9b%b4%ef%bc%88HDR%ef%bc%89%e6%88%90%e5%83%8f&body=Check out this article: https%3a%2f%2falili.tech%2farchive%2f855c5353%2f"><i class="fa fa-envelope" aria-hidden="true"></i></a></li><li><a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2falili.tech%2farchive%2f855c5353%2f&title=%e4%bd%bf%e7%94%a8%20OpenCV%20%e8%bf%9b%e8%a1%8c%e9%ab%98%e5%8a%a8%e6%80%81%e8%8c%83%e5%9b%b4%ef%bc%88HDR%ef%bc%89%e6%88%90%e5%83%8f"><i class="fa fa-get-pocket" aria-hidden="true"></i></a></li><li><a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2falili.tech%2farchive%2f855c5353%2f&title=%e4%bd%bf%e7%94%a8%20OpenCV%20%e8%bf%9b%e8%a1%8c%e9%ab%98%e5%8a%a8%e6%80%81%e8%8c%83%e5%9b%b4%ef%bc%88HDR%ef%bc%89%e6%88%90%e5%83%8f"><i class="fa fa-reddit" aria-hidden="true"></i></a></li><li><a class="icon" href="http://www.stumbleupon.com/submit?url=https%3a%2f%2falili.tech%2farchive%2f855c5353%2f&title=%e4%bd%bf%e7%94%a8%20OpenCV%20%e8%bf%9b%e8%a1%8c%e9%ab%98%e5%8a%a8%e6%80%81%e8%8c%83%e5%9b%b4%ef%bc%88HDR%ef%bc%89%e6%88%90%e5%83%8f"><i class="fa fa-stumbleupon" aria-hidden="true"></i></a></li><li><a class="icon" href="http://digg.com/submit?url=https%3a%2f%2falili.tech%2farchive%2f855c5353%2f&title=%e4%bd%bf%e7%94%a8%20OpenCV%20%e8%bf%9b%e8%a1%8c%e9%ab%98%e5%8a%a8%e6%80%81%e8%8c%83%e5%9b%b4%ef%bc%88HDR%ef%bc%89%e6%88%90%e5%83%8f"><i class="fa fa-digg" aria-hidden="true"></i></a></li></ul></div><div id="toc"><nav id="TableOfContents"><ul><li><a href="#版权声明">版权声明</a></li></ul></nav></div></span></div><div class="content index width mx-auto px3 my3"><section id="wrapper" class="home"><article class="post" itemscope itemtype="http://schema.org/BlogPosting"><header><h1 class="posttitle" itemprop="name headline">使用 OpenCV 进行高动态范围（HDR）成像</h1><div class="meta"><div class="postdate"><time datetime="2018-10-18" itemprop="datePublished">2018-10-18</time></div><div class="article-tag"><i class="fa fa-eye"></i> <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span></span></div><div class="article-tag-box"></div></div></header><div class="content" itemprop="articleBody"><div id="raw"><p style="opacity: 0;">Alili | 前端大爆炸! - WEB BANG! BANG!! BANG!!! 前端大爆炸,一个前端技术博客.想到哪,学到哪,写到哪. 本文资源来源互联网，仅供学习研究使用，版权归该资源的合法拥有者所有， Alili, 前端大爆炸, WEB BANG BANG BANG, web前端博客, 前端模块化, 前端工程化, 前端数据监控, 性能优化, 网页制作, 前端, js, html5, css, 踩坑小报告, 微前端, 树莓派, 前端开发, 区块链, 网络, Mongodb, Vue.js, Angular.js, node.js</p><script>$(function () {
            var html = "\n\n            \x3ch1\x3e\x3ca href=\x22#使用-opencv-进行高动态范围hdr成像\x22\x3e\x3c\/a\x3e使用 OpenCV 进行高动态范围（HDR）成像\x3c\/h1\x3e\n\x3cp\x3e在本教程中，我们将学习如何使用由不同曝光设置拍摄的多张图像创建高动态范围High Dynamic Range（HDR）图像。 我们将以 C\x2b\x2b 和 Python 两种形式分享代码。\x3c\/p\x3e\n\x3ch3\x3e\x3ca href=\x22#什么是高动态范围成像\x22\x3e\x3c\/a\x3e什么是高动态范围成像？\x3c\/h3\x3e\n\x3cp\x3e大多数数码相机和显示器都是按照 24 位矩阵捕获或者显示彩色图像。 每个颜色通道有 8 位，因此每个通道的像素值在 0-255 范围内。 换句话说，普通的相机或者显示器的动态范围是有限的。\x3c\/p\x3e\n\x3cp\x3e但是，我们周围世界动态范围极大。 在车库内关灯就会变黑，直接看着太阳就会变得非常亮。 即使不考虑这些极端，在日常情况下，8 位的通道勉强可以捕捉到现场场景。 因此，相机会尝试去评估光照并且自动设置曝光，这样图像的最关注区域就会有良好的动态范围，并且太暗和太亮的部分会被相应截取为 0 和 255。\x3c\/p\x3e\n\x3cp\x3e在下图中，左侧的图像是正常曝光的图像。 请注意，由于相机决定使用拍摄主体（我的儿子）的设置，所以背景中的天空已经完全流失了，但是明亮的天空也因此被刷掉了。 右侧的图像是由 iPhone 生成的HDR图像。\x3c\/p\x3e\n\x3cp\x3e\x3ca href=\x22http:\/\/www.learnopencv.com\/wp-content\/uploads\/2017\/09\/high-dynamic-range-hdr.jpg\x22\x3e\x3cimg src=\x22https:\/\/p0.ssl.qhimg.com\/t01e438d59d57cea30e.jpg\x22 alt=\x22High Dynamic Range (HDR)\x22\x3e\x3c\/a\x3e\x3c\/p\x3e\n\x3cp\x3eiPhone 是如何拍摄 HDR 图像的呢？ 它实际上采用三种不同的曝光度拍摄了 3 张图像，3 张图像拍摄非常迅速，在 3 张图像之间几乎没有产生位移。然后组合三幅图像来产生 HDR 图像。 我们将在下一节看到一些细节。\x3c\/p\x3e\n\x3cblockquote\x3e\n\x3cp\x3e将在不同曝光设置下获取的相同场景的不同图像组合的过程称为高动态范围（HDR）成像。\x3c\/p\x3e\n\x3c\/blockquote\x3e\n\x3ch3\x3e\x3ca href=\x22#高动态范围hdr成像是如何工作的\x22\x3e\x3c\/a\x3e高动态范围（HDR）成像是如何工作的？\x3c\/h3\x3e\n\x3cp\x3e在本节中，我们来看下使用 OpenCV 创建 HDR 图像的步骤。\x3c\/p\x3e\n\x3cblockquote\x3e\n\x3cp\x3e要想轻松学习本教程，请点击\x3ca href=\x22http:\/\/www.learnopencv.com\/wp-content\/uploads\/2017\/10\/hdr.zip\x22\x3e此处\x3c\/a\x3e\x3ca href=\x22http:\/\/www.learnopencv.com\/wp-content\/uploads\/2017\/10\/hdr.zip\x22\x3e下载\x3c\/a\x3e C\x2b\x2b 和 Python 代码还有图像。 如果您有兴趣了解更多关于人工智能，计算机视觉和机器学习的信息，请\x3ca href=\x22https:\/\/bigvisionllc.leadpages.net\/leadbox\/143948b73f72a2%3A173c9390c346dc\/5649050225344512\/\x22\x3e订阅\x3c\/a\x3e我们的电子杂志。\x3c\/p\x3e\n\x3c\/blockquote\x3e\n\x3ch3\x3e\x3ca href=\x22#第-1-步捕获不同曝光度的多张图像\x22\x3e\x3c\/a\x3e第 1 步：捕获不同曝光度的多张图像\x3c\/h3\x3e\n\x3cp\x3e当我们使用相机拍照时，每个通道只有 8 位来表示场景的动态范围（亮度范围）。 但是，通过改变快门速度，我们可以在不同的曝光条件下拍摄多个场景图像。 大多数单反相机（SLR）有一个功能称为自动包围式曝光Auto Exposure Bracketing（AEB），只需按一下按钮，我们就可以在不同的曝光下拍摄多张照片。 如果你正在使用 iPhone，你可以使用这个\x3ca href=\x22https:\/\/itunes.apple.com\/us\/app\/autobracket-hdr\/id923626339?mt=8\x26amp;ign-mpt=uo%3D8\x22\x3e自动包围式 HDR 应用程序\x3c\/a\x3e，如果你是一个 Android 用户，你可以尝试一个\x3ca href=\x22https:\/\/play.google.com\/store\/apps\/details?id=com.almalence.opencam\x26amp;hl=en\x22\x3e更好的相机应用程序\x3c\/a\x3e。\x3c\/p\x3e\n\x3cp\x3e场景没有变化时，在相机上使用自动包围式曝光或在手机上使用自动包围式应用程序，我们可以一张接一张地快速拍摄多张照片。 当我们在 iPhone 中使用 HDR 模式时，会拍摄三张照片。\x3c\/p\x3e\n\x3col\x3e\n\x3cli\x3e曝光不足的图像：该图像比正确曝光的图像更暗。 目标是捕捉非常明亮的图像部分。\x3c\/li\x3e\n\x3cli\x3e正确曝光的图像：这是相机将根据其估计的照明拍摄的常规图像。\x3c\/li\x3e\n\x3cli\x3e曝光过度的图像：该图像比正确曝光的图像更亮。 目标是拍摄非常黑暗的图像部分。\x3c\/li\x3e\n\x3c\/ol\x3e\n\x3cp\x3e但是，如果场景的动态范围很大，我们可以拍摄三张以上的图片来合成 HDR 图像。 在本教程中，我们将使用曝光时间为1\/30 秒，0.25 秒，2.5 秒和 15 秒的 4 张图像。 缩略图如下所示。\x3c\/p\x3e\n\x3cp\x3e\x3ca href=\x22http:\/\/www.learnopencv.com\/wp-content\/uploads\/2017\/10\/hdr-image-sequence.jpg\x22\x3e\x3cimg src=\x22https:\/\/p0.ssl.qhimg.com\/t01ec3a255b434c2109.jpg\x22 alt=\x22Auto Exposure Bracketed  HDR image sequence\x22\x3e\x3c\/a\x3e\x3c\/p\x3e\n\x3cp\x3e单反相机或手机的曝光时间和其他设置的信息通常存储在 JPEG 文件的 EXIF 元数据中。 查看此\x3ca href=\x22https:\/\/www.howtogeek.com\/289712\/how-to-see-an-images-exif-data-in-windows-and-macos\x22\x3e链接\x3c\/a\x3e可在 Windows 和 Mac 中查看存储在 JPEG 文件中的 EXIF 元数据。 或者，您可以使用我最喜欢的名为 \x3ca href=\x22https:\/\/www.sno.phy.queensu.ca\/%7Ephil\/exiftool\x22\x3eEXIFTOOL\x3c\/a\x3e 的查看 EXIF 的命令行工具。\x3c\/p\x3e\n\x3cp\x3e我们先从读取分配到不同曝光时间的图像开始。\x3c\/p\x3e\n\x3cp\x3e\x3cstrong\x3eC\x2b\x2b\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs cpp\x22\x3e\x3cspan class=\x22hljs-function\x22\x3e\x3cspan class=\x22hljs-keyword\x22\x3evoid\x3c\/span\x3e \x3cspan class=\x22hljs-title\x22\x3ereadImagesAndTimes\x3c\/span\x3e\x3cspan class=\x22hljs-params\x22\x3e(\x3cspan class=\x22hljs-built_in\x22\x3evector\x3c\/span\x3e\x26lt;Mat\x26gt; \x26amp;images, \x3cspan class=\x22hljs-built_in\x22\x3evector\x3c\/span\x3e\x26lt;\x3cspan class=\x22hljs-keyword\x22\x3efloat\x3c\/span\x3e\x26gt; \x26amp;times)\x3c\/span\x3e\n\x3c\/span\x3e{\n\n  \x3cspan class=\x22hljs-keyword\x22\x3eint\x3c\/span\x3e numImages = \x3cspan class=\x22hljs-number\x22\x3e4\x3c\/span\x3e;\n\n  \x3cspan class=\x22hljs-comment\x22\x3e\/\/ 曝光时间列表\x3c\/span\x3e\n  \x3cspan class=\x22hljs-keyword\x22\x3estatic\x3c\/span\x3e \x3cspan class=\x22hljs-keyword\x22\x3econst\x3c\/span\x3e \x3cspan class=\x22hljs-keyword\x22\x3efloat\x3c\/span\x3e timesArray[] = {\x3cspan class=\x22hljs-number\x22\x3e1\x3c\/span\x3e\/\x3cspan class=\x22hljs-number\x22\x3e30.0f\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e0.25\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e2.5\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e15.0\x3c\/span\x3e};\n  times.assign(timesArray, timesArray \x2b numImages);\n\n  \x3cspan class=\x22hljs-comment\x22\x3e\/\/ 图像文件名称列表\x3c\/span\x3e\n  \x3cspan class=\x22hljs-keyword\x22\x3estatic\x3c\/span\x3e \x3cspan class=\x22hljs-keyword\x22\x3econst\x3c\/span\x3e \x3cspan class=\x22hljs-keyword\x22\x3echar\x3c\/span\x3e* filenames[] = {\x3cspan class=\x22hljs-string\x22\x3e\x22img_0.033.jpg\x22\x3c\/span\x3e, \x3cspan class=\x22hljs-string\x22\x3e\x22img_0.25.jpg\x22\x3c\/span\x3e, \x3cspan class=\x22hljs-string\x22\x3e\x22img_2.5.jpg\x22\x3c\/span\x3e, \x3cspan class=\x22hljs-string\x22\x3e\x22img_15.jpg\x22\x3c\/span\x3e};\n  \x3cspan class=\x22hljs-keyword\x22\x3efor\x3c\/span\x3e(\x3cspan class=\x22hljs-keyword\x22\x3eint\x3c\/span\x3e i=\x3cspan class=\x22hljs-number\x22\x3e0\x3c\/span\x3e; i \x26lt; numImages; i\x2b\x2b)\n  {\n    Mat im = imread(filenames[i]);\n    images.push_back(im);\n  }\n\n}\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e\x3cstrong\x3ePython\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs ruby\x22\x3e\x3cspan class=\x22hljs-function\x22\x3e\x3cspan class=\x22hljs-keyword\x22\x3edef\x3c\/span\x3e \x3cspan class=\x22hljs-title\x22\x3ereadImagesAndTimes\x3c\/span\x3e\x3cspan class=\x22hljs-params\x22\x3e()\x3c\/span\x3e\x3c\/span\x3e:\n  \x3cspan class=\x22hljs-comment\x22\x3e# 曝光时间列表\x3c\/span\x3e\n  times = np.array([ \x3cspan class=\x22hljs-number\x22\x3e1\x3c\/span\x3e\/\x3cspan class=\x22hljs-number\x22\x3e30.0\x3c\/span\x3e, \x3cspan class=\x22hljs-number\x22\x3e0\x3c\/span\x3e.\x3cspan class=\x22hljs-number\x22\x3e25\x3c\/span\x3e, \x3cspan class=\x22hljs-number\x22\x3e2.5\x3c\/span\x3e, \x3cspan class=\x22hljs-number\x22\x3e15.0\x3c\/span\x3e ], dtype=np.float32)\n\n  \x3cspan class=\x22hljs-comment\x22\x3e# 图像文件名称列表\x3c\/span\x3e\n  filenames = [\x3cspan class=\x22hljs-string\x22\x3e\x22img_0.033.jpg\x22\x3c\/span\x3e, \x3cspan class=\x22hljs-string\x22\x3e\x22img_0.25.jpg\x22\x3c\/span\x3e, \x3cspan class=\x22hljs-string\x22\x3e\x22img_2.5.jpg\x22\x3c\/span\x3e, \x3cspan class=\x22hljs-string\x22\x3e\x22img_15.jpg\x22\x3c\/span\x3e]\n  images = []\n  \x3cspan class=\x22hljs-keyword\x22\x3efor\x3c\/span\x3e filename \x3cspan class=\x22hljs-keyword\x22\x3ein\x3c\/span\x3e \x3cspan class=\x22hljs-symbol\x22\x3efilenames:\x3c\/span\x3e\n    im = cv2.imread(filename)\n    images.append(im)\n\n  \x3cspan class=\x22hljs-keyword\x22\x3ereturn\x3c\/span\x3e images, times\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3ch3\x3e\x3ca href=\x22#第-2-步对齐图像\x22\x3e\x3c\/a\x3e第 2 步：对齐图像\x3c\/h3\x3e\n\x3cp\x3e合成 HDR 图像时使用的图像如果未对齐可能会导致严重的伪影。 在下图中，左侧的图像是使用未对齐的图像组成的 HDR 图像，右侧的图像是使用对齐的图像的图像。 通过放大图像的一部分（使用红色圆圈显示的）我们会在左侧图像中看到严重的鬼影。\x3c\/p\x3e\n\x3cp\x3e\x3ca href=\x22http:\/\/www.learnopencv.com\/wp-content\/uploads\/2017\/10\/aligned-unaligned-hdr-comparison.jpg\x22\x3e\x3cimg src=\x22https:\/\/p0.ssl.qhimg.com\/t016150a7632cecde54.jpg\x22 alt=\x22Misalignment problem in HDR\x22\x3e\x3c\/a\x3e\x3c\/p\x3e\n\x3cp\x3e在拍摄照片制作 HDR 图像时，专业摄影师自然是将相机安装在三脚架上。 他们还使用称为\x3ca href=\x22https:\/\/www.slrlounge.com\/workshop\/using-mirror-up-mode-mirror-lockup\x22\x3e镜像锁定\x3c\/a\x3e功能来减少额外的振动。 即使如此，图像可能仍然没有完美对齐，因为没有办法保证无振动的环境。 使用手持相机或手机拍摄图像时，对齐问题会变得更糟。\x3c\/p\x3e\n\x3cp\x3e幸运的是，OpenCV 提供了一种简单的方法，使用 \x3ccode\x3eAlignMTB\x3c\/code\x3e 对齐这些图像。 该算法将所有图像转换为中值阈值位图median threshold bitmaps（MTB）。 图像的 MTB 生成方式为将比中值亮度的更亮的分配为 1，其余为 0。 MTB 不随曝光时间的改变而改变。 因此不需要我们指定曝光时间就可以对齐 MTB。\x3c\/p\x3e\n\x3cp\x3e基于 MTB 的对齐方式的代码如下。\x3c\/p\x3e\n\x3cp\x3e\x3cstrong\x3eC\x2b\x2b\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs xl\x22\x3e\x3cspan class=\x22hljs-comment\x22\x3e\/\/ 对齐输入图像\x3c\/span\x3e\nPtr\x26lt;AlignMTB\x26gt; alignMTB = createAlignMTB();\n\x3cspan class=\x22hljs-function\x22\x3e\x3cspan class=\x22hljs-title\x22\x3ealignMTB\x3c\/span\x3e-\x26gt;\x3c\/span\x3eprocess(images, images);\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e\x3cstrong\x3ePython\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs makefile\x22\x3e\x3cspan class=\x22hljs-comment\x22\x3e# 对齐输入图像\x3c\/span\x3e\nalignMTB = cv2.createAlignMTB()\nalignMTB.process(images, images)\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3ch3\x3e\x3ca href=\x22#第-3-步提取相机响应函数\x22\x3e\x3c\/a\x3e第 3 步：提取相机响应函数\x3c\/h3\x3e\n\x3cp\x3e典型相机的响应与场景亮度不成线性关系。 那是什么意思呢？ 假设有两个物体由同一个相机拍摄，在现实世界中其中一个物体是另一个物体亮度的两倍。 当您测量照片中两个物体的像素亮度时，较亮物体的像素值将不会是较暗物体的两倍。 在不估计相机响应函数Camera Response Function（CRF）的情况下，我们将无法将图像合并到一个HDR图像中。\x3c\/p\x3e\n\x3cp\x3e将多个曝光图像合并为 HDR 图像意味着什么？\x3c\/p\x3e\n\x3cp\x3e只考虑图像的某个位置 \x3ccode\x3e(x,y)\x3c\/code\x3e 一个像素。 如果 CRF 是线性的，则像素值将直接与曝光时间成比例，除非像素在特定图像中太暗（即接近 0）或太亮（即接近 255）。 我们可以过滤出这些不好的像素（太暗或太亮），并且将像素值除以曝光时间来估计像素的亮度，然后在像素不差的（太暗或太亮）所有图像上对亮度值取平均。我们可以对所有像素进行这样的处理，并通过对“好”像素进行平均来获得所有像素的单张图像。\x3c\/p\x3e\n\x3cp\x3e但是 CRF 不是线性的， 我们需要评估 CRF 把图像强度变成线性，然后才能合并或者平均它们。\x3c\/p\x3e\n\x3cp\x3e好消息是，如果我们知道每个图像的曝光时间，则可以从图像估计 CRF。 与计算机视觉中的许多问题一样，找到 CRF 的问题本质是一个最优解问题，其目标是使由数据项和平滑项组成的目标函数最小化。 这些问题通常会降维到线性最小二乘问题，这些问题可以使用奇异值分解Singular Value Decomposition（SVD）来解决，奇异值分解是所有线性代数包的一部分。 CRF 提取算法的细节在\x3ca href=\x22http:\/\/www.pauldebevec.com\/Research\/HDR\/debevec-siggraph97.pdf\x22\x3e从照片提取高动态范围辐射图\x3c\/a\x3e这篇论文中可以找到。\x3c\/p\x3e\n\x3cp\x3e使用 OpenCV 的 \x3ccode\x3eCalibrateDebevec\x3c\/code\x3e 或者 \x3ccode\x3eCalibrateRobertson\x3c\/code\x3e 就可以用 2 行代码找到 CRF。本篇教程中我们使用 \x3ccode\x3eCalibrateDebevec\x3c\/code\x3e\x3c\/p\x3e\n\x3cp\x3e\x3cstrong\x3eC\x2b\x2b\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs shell\x22\x3e\/\/ 获取图像响应函数 (CRF)\nMat responseDebevec;\nPtr\x26lt;CalibrateDebevec\x26gt; calibrateDebevec = createCalibrateDebevec();\n\x3cspan class=\x22hljs-meta\x22\x3ecalibrateDebevec-\x26gt;\x3c\/span\x3e\x3cspan class=\x22bash\x22\x3eprocess(images, responseDebevec, \x3cspan class=\x22hljs-built_in\x22\x3etimes\x3c\/span\x3e);\x3c\/span\x3e\n\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e\x3cstrong\x3ePython\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs ini\x22\x3e\x3cspan class=\x22hljs-comment\x22\x3e# 获取图像响应函数 (CRF)\x3c\/span\x3e\n\x3cspan class=\x22hljs-attr\x22\x3ecalibrateDebevec\x3c\/span\x3e = cv2.createCalibrateDebevec()\n\x3cspan class=\x22hljs-attr\x22\x3eresponseDebevec\x3c\/span\x3e = calibrateDebevec.process(images, times)\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e下图显示了使用红绿蓝通道的图像提取的 CRF。\x3c\/p\x3e\n\x3cp\x3e\x3ca href=\x22http:\/\/www.learnopencv.com\/wp-content\/uploads\/2017\/10\/camera-response-function.jpg\x22\x3e\x3cimg src=\x22https:\/\/p0.ssl.qhimg.com\/t01f7d0e42bf54d3d16.jpg\x22 alt=\x22Camera Response Function\x22\x3e\x3c\/a\x3e\x3c\/p\x3e\n\x3ch3\x3e\x3ca href=\x22#第-4-步合并图像\x22\x3e\x3c\/a\x3e第 4 步：合并图像\x3c\/h3\x3e\n\x3cp\x3e一旦 CRF 评估结束，我们可以使用 \x3ccode\x3eMergeDebevec\x3c\/code\x3e 将曝光图像合并成一个HDR图像。 C\x2b\x2b 和 Python 代码如下所示。\x3c\/p\x3e\n\x3cp\x3e\x3cstrong\x3eC\x2b\x2b\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs gcode\x22\x3e\x3cspan class=\x22hljs-comment\x22\x3e\/\/ 将图像合并为HDR线性图像\x3c\/span\x3e\nMat hdrDebevec;\nPtr\x26lt;MergeDebevec\x26gt; mergeDebevec = createMergeDebevec\x3cspan class=\x22hljs-comment\x22\x3e()\x3c\/span\x3e;\nmergeDebevec-\x26gt;process\x3cspan class=\x22hljs-comment\x22\x3e(images, hdrDebevec, times, responseDebevec)\x3c\/span\x3e;\n\x3cspan class=\x22hljs-comment\x22\x3e\/\/ 保存图像\x3c\/span\x3e\nimwrite\x3cspan class=\x22hljs-comment\x22\x3e(\x22hdrDebevec.hdr\x22, hdrDebevec)\x3c\/span\x3e;\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e\x3cstrong\x3ePython\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs makefile\x22\x3e\x3cspan class=\x22hljs-comment\x22\x3e# 将图像合并为HDR线性图像\x3c\/span\x3e\nmergeDebevec = cv2.createMergeDebevec()\nhdrDebevec = mergeDebevec.process(images, times, responseDebevec)\n\x3cspan class=\x22hljs-comment\x22\x3e# 保存图像\x3c\/span\x3e\ncv2.imwrite(\x3cspan class=\x22hljs-string\x22\x3e\x22hdrDebevec.hdr\x22\x3c\/span\x3e, hdrDebevec)\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e上面保存的 HDR 图像可以在 Photoshop 中加载并进行色调映射。示例图像如下所示。\x3c\/p\x3e\n\x3cp\x3e\x3ca href=\x22http:\/\/www.learnopencv.com\/wp-content\/uploads\/2017\/10\/hdr-Photoshop-Tonemapping.jpg\x22\x3e\x3cimg src=\x22https:\/\/p0.ssl.qhimg.com\/t0170ec4e9b42f495be.jpg\x22 alt=\x22HDR Photoshop tone mapping\x22\x3e\x3c\/a\x3e\x3c\/p\x3e\n\x3cp\x3e\x3cem\x3eHDR Photoshop 色调映射\x3c\/em\x3e\x3c\/p\x3e\n\x3ch3\x3e\x3ca href=\x22#第-5-步色调映射\x22\x3e\x3c\/a\x3e第 5 步：色调映射\x3c\/h3\x3e\n\x3cp\x3e现在我们已经将我们的曝光图像合并到一个 HDR 图像中。 你能猜出这个图像的最小和最大像素值吗？ 对于黑色条件，最小值显然为 0。 理论最大值是什么？ 无限大！ 在实践中，不同情况下的最大值是不同的。 如果场景包含非常明亮的光源，那么最大值就会非常大。\x3c\/p\x3e\n\x3cp\x3e尽管我们已经使用多个图像恢复了相对亮度信息，但是我们现在又面临了新的挑战：将这些信息保存为 24 位图像用于显示。\x3c\/p\x3e\n\x3cp\x3e将高动态范围（HDR）图像转换为 8 位单通道图像的过程称为色调映射。这个过程的同时还需要保留尽可能多的细节。\x3c\/p\x3e\n\x3cp\x3e有几种色调映射算法。 OpenCV 实现了其中的四个。 要记住的是没有一个绝对正确的方法来做色调映射。 通常，我们希望在色调映射图像中看到比任何一个曝光图像更多的细节。 有时色调映射的目标是产生逼真的图像，而且往往是产生超现实图像的目标。 在 OpenCV 中实现的算法倾向于产生现实的并不那么生动的结果。\x3c\/p\x3e\n\x3cp\x3e我们来看看各种选项。 以下列出了不同色调映射算法的一些常见参数。\x3c\/p\x3e\n\x3col\x3e\n\x3cli\x3e伽马gamma：该参数通过应用伽马校正来压缩动态范围。 当伽马等于 1 时，不应用修正。 小于 1 的伽玛会使图像变暗，而大于 1 的伽马会使图像变亮。\x3c\/li\x3e\n\x3cli\x3e饱和度saturation：该参数用于增加或减少饱和度。 饱和度高时，色彩更丰富，更浓。 饱和度值接近零，使颜色逐渐消失为灰度。\x3c\/li\x3e\n\x3cli\x3e对比度contrast：控制输出图像的对比度（即 \x3ccode\x3elog(maxPixelValue\/minPixelValue)\x3c\/code\x3e）。\x3c\/li\x3e\n\x3c\/ol\x3e\n\x3cp\x3e让我们来探索 OpenCV 中可用的四种色调映射算法。\x3c\/p\x3e\n\x3ch4\x3e\x3ca href=\x22#drago-色调映射\x22\x3e\x3c\/a\x3eDrago 色调映射\x3c\/h4\x3e\n\x3cp\x3eDrago 色调映射的参数如下所示：\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs lsl\x22\x3ecreateTonemapDrago\n(\n\x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e   gamma = \x3cspan class=\x22hljs-number\x22\x3e1.0\x3c\/span\x3ef,\n\x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e   saturation = \x3cspan class=\x22hljs-number\x22\x3e1.0\x3c\/span\x3ef,\n\x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e   bias = \x3cspan class=\x22hljs-number\x22\x3e0.85\x3c\/span\x3ef \n)   \n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e这里，\x3ccode\x3ebias\x3c\/code\x3e 是 \x3ccode\x3e[0, 1]\x3c\/code\x3e 范围内偏差函数的值。 从 0.7 到 0.9 的值通常效果较好。 默认值是 0.85。 有关更多技术细节，请参阅这篇\x3ca href=\x22http:\/\/resources.mpi-inf.mpg.de\/tmo\/logmap\/logmap.pdf\x22\x3e论文\x3c\/a\x3e。\x3c\/p\x3e\n\x3cp\x3eC\x2b\x2b 和 Python 代码如下所示。 参数是通过反复试验获得的。 最后的结果乘以 3 只是因为它给出了最令人满意的结果。\x3c\/p\x3e\n\x3cp\x3e\x3cstrong\x3eC\x2b\x2b\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs armasm\x22\x3e\/\/ 使用Drago色调映射算法获得\x3cspan class=\x22hljs-number\x22\x3e24\x3c\/span\x3e位彩色图像\n\x3cspan class=\x22hljs-symbol\x22\x3eMat\x3c\/span\x3e \x3cspan class=\x22hljs-keyword\x22\x3eldrDrago;\n\x3c\/span\x3e\x3cspan class=\x22hljs-symbol\x22\x3ePtr\x3c\/span\x3e\x26lt;TonemapDrago\x26gt; tonemapDrago = createTonemapDrago(\x3cspan class=\x22hljs-number\x22\x3e1\x3c\/span\x3e.\x3cspan class=\x22hljs-number\x22\x3e0\x3c\/span\x3e, \x3cspan class=\x22hljs-number\x22\x3e0\x3c\/span\x3e.\x3cspan class=\x22hljs-number\x22\x3e7\x3c\/span\x3e)\x3cspan class=\x22hljs-comment\x22\x3e;\x3c\/span\x3e\n\x3cspan class=\x22hljs-symbol\x22\x3etonemapDrago\x3c\/span\x3e-\x26gt;process(hdrDebevec, \x3cspan class=\x22hljs-keyword\x22\x3eldrDrago);\n\x3c\/span\x3e\x3cspan class=\x22hljs-keyword\x22\x3eldrDrago \x3c\/span\x3e= \x3cspan class=\x22hljs-number\x22\x3e3\x3c\/span\x3e * \x3cspan class=\x22hljs-keyword\x22\x3eldrDrago;\n\x3c\/span\x3e\x3cspan class=\x22hljs-symbol\x22\x3eimwrite\x3c\/span\x3e(\x3cspan class=\x22hljs-string\x22\x3e\x22ldr-Drago.jpg\x22\x3c\/span\x3e, \x3cspan class=\x22hljs-keyword\x22\x3eldrDrago \x3c\/span\x3e* \x3cspan class=\x22hljs-number\x22\x3e255\x3c\/span\x3e)\x3cspan class=\x22hljs-comment\x22\x3e;\x3c\/span\x3e\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e\x3cstrong\x3ePython\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs makefile\x22\x3e\x3cspan class=\x22hljs-comment\x22\x3e# 使用Drago色调映射算法获得24位彩色图像\x3c\/span\x3e\ntonemapDrago = cv2.createTonemapDrago(1.0, 0.7)\nldrDrago = tonemapDrago.process(hdrDebevec)\nldrDrago = 3 * ldrDrago\ncv2.imwrite(\x3cspan class=\x22hljs-string\x22\x3e\x22ldr-Drago.jpg\x22\x3c\/span\x3e, ldrDrago * 255)\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e结果如下：\x3c\/p\x3e\n\x3cp\x3e\x3ca href=\x22http:\/\/www.learnopencv.com\/wp-content\/uploads\/2017\/10\/hdr-Drago.jpg\x22\x3e\x3cimg src=\x22https:\/\/p0.ssl.qhimg.com\/t018b62eb20529d62f8.jpg\x22 alt=\x22HDR tone mapping using Drago\x27s algorithm\x22\x3e\x3c\/a\x3e\x3c\/p\x3e\n\x3cp\x3e\x3cem\x3e使用Drago算法的HDR色调映射\x3c\/em\x3e\x3c\/p\x3e\n\x3ch4\x3e\x3ca href=\x22#durand-色调映射\x22\x3e\x3c\/a\x3eDurand 色调映射\x3c\/h4\x3e\n\x3cp\x3eDurand 色调映射的参数如下所示：\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs lsl\x22\x3ecreateTonemapDurand \n(   \n  \x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e     gamma = \x3cspan class=\x22hljs-number\x22\x3e1.0\x3c\/span\x3ef, \n  \x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e     contrast = \x3cspan class=\x22hljs-number\x22\x3e4.0\x3c\/span\x3ef,\n  \x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e     saturation = \x3cspan class=\x22hljs-number\x22\x3e1.0\x3c\/span\x3ef,\n  \x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e     sigma_space = \x3cspan class=\x22hljs-number\x22\x3e2.0\x3c\/span\x3ef,\n  \x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e     sigma_color = \x3cspan class=\x22hljs-number\x22\x3e2.0\x3c\/span\x3ef \n); \n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e该算法基于将图像分解为基础层和细节层。 使用称为双边滤波器的边缘保留滤波器来获得基本层。 \x3ccode\x3esigma_space\x3c\/code\x3e 和\x3ccode\x3esigma_color\x3c\/code\x3e 是双边滤波器的参数，分别控制空间域和彩色域中的平滑量。\x3c\/p\x3e\n\x3cp\x3e有关更多详细信息，请查看这篇\x3ca href=\x22https:\/\/people.csail.mit.edu\/fredo\/PUBLI\/Siggraph2002\/DurandBilateral.pdf\x22\x3e论文\x3c\/a\x3e。\x3c\/p\x3e\n\x3cp\x3e\x3cstrong\x3eC\x2b\x2b\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs lsl\x22\x3e\x3cspan class=\x22hljs-comment\x22\x3e\/\/ 使用Durand色调映射算法获得24位彩色图像\x3c\/span\x3e\nMat ldrDurand;\nPtr\x26lt;TonemapDurand\x26gt; tonemapDurand = createTonemapDurand(\x3cspan class=\x22hljs-number\x22\x3e1.5\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e4\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e1.0\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e1\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e1\x3c\/span\x3e);\ntonemapDurand-\x26gt;process(hdrDebevec, ldrDurand);\nldrDurand = \x3cspan class=\x22hljs-number\x22\x3e3\x3c\/span\x3e * ldrDurand;\nimwrite(\x3cspan class=\x22hljs-string\x22\x3e\x22ldr-Durand.jpg\x22\x3c\/span\x3e, ldrDurand * \x3cspan class=\x22hljs-number\x22\x3e255\x3c\/span\x3e);\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e\x3cstrong\x3ePython\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs lsl\x22\x3e# 使用Durand色调映射算法获得\x3cspan class=\x22hljs-number\x22\x3e24\x3c\/span\x3e位彩色图像\n tonemapDurand = cv2.createTonemapDurand(\x3cspan class=\x22hljs-number\x22\x3e1.5\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e4\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e1.0\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e1\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e1\x3c\/span\x3e)\n ldrDurand = tonemapDurand.process(hdrDebevec)\n ldrDurand = \x3cspan class=\x22hljs-number\x22\x3e3\x3c\/span\x3e * ldrDurand\n cv2.imwrite(\x3cspan class=\x22hljs-string\x22\x3e\x22ldr-Durand.jpg\x22\x3c\/span\x3e, ldrDurand * \x3cspan class=\x22hljs-number\x22\x3e255\x3c\/span\x3e)\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e结果如下：\x3c\/p\x3e\n\x3cp\x3e\x3ca href=\x22http:\/\/www.learnopencv.com\/wp-content\/uploads\/2017\/10\/hdr-Durand.jpg\x22\x3e\x3cimg src=\x22https:\/\/p0.ssl.qhimg.com\/t012d6724a7d21f3d43.jpg\x22 alt=\x22HDR tone mapping using Durand\x27s algorithm\x22\x3e\x3c\/a\x3e\x3c\/p\x3e\n\x3cp\x3e\x3cem\x3e使用Durand算法的HDR色调映射\x3c\/em\x3e\x3c\/p\x3e\n\x3ch4\x3e\x3ca href=\x22#reinhard-色调映射\x22\x3e\x3c\/a\x3eReinhard 色调映射\x3c\/h4\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs lsl\x22\x3e\ncreateTonemapReinhard\n(\n\x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e   gamma = \x3cspan class=\x22hljs-number\x22\x3e1.0\x3c\/span\x3ef,\n\x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e   intensity = \x3cspan class=\x22hljs-number\x22\x3e0.0\x3c\/span\x3ef,\n\x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e   light_adapt = \x3cspan class=\x22hljs-number\x22\x3e1.0\x3c\/span\x3ef,\n\x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e   color_adapt = \x3cspan class=\x22hljs-number\x22\x3e0.0\x3c\/span\x3ef \n)   \n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e\x3ccode\x3eintensity\x3c\/code\x3e 参数应在 \x3ccode\x3e[-8, 8]\x3c\/code\x3e 范围内。 更高的亮度值会产生更明亮的结果。 \x3ccode\x3elight_adapt\x3c\/code\x3e 控制灯光，范围为 \x3ccode\x3e[0, 1]\x3c\/code\x3e。 值 1 表示仅基于像素值的自适应，而值 0 表示全局自适应。 中间值可以用于两者的加权组合。 参数 \x3ccode\x3ecolor_adapt\x3c\/code\x3e 控制色彩，范围为 \x3ccode\x3e[0, 1]\x3c\/code\x3e。 如果值被设置为 1，则通道被独立处理，如果该值被设置为 0，则每个通道的适应级别相同。中间值可以用于两者的加权组合。\x3c\/p\x3e\n\x3cp\x3e有关更多详细信息，请查看这篇\x3ca href=\x22http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.106.8100\x26amp;rep=rep1\x26amp;type=pdf\x22\x3e论文\x3c\/a\x3e。\x3c\/p\x3e\n\x3cp\x3e\x3cstrong\x3eC\x2b\x2b\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs lsl\x22\x3e\x3cspan class=\x22hljs-comment\x22\x3e\/\/ 使用Reinhard色调映射算法获得24位彩色图像\x3c\/span\x3e\nMat ldrReinhard;\nPtr\x26lt;TonemapReinhard\x26gt; tonemapReinhard = createTonemapReinhard(\x3cspan class=\x22hljs-number\x22\x3e1.5\x3c\/span\x3e, \x3cspan class=\x22hljs-number\x22\x3e0\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e0\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e0\x3c\/span\x3e);\ntonemapReinhard-\x26gt;process(hdrDebevec, ldrReinhard);\nimwrite(\x3cspan class=\x22hljs-string\x22\x3e\x22ldr-Reinhard.jpg\x22\x3c\/span\x3e, ldrReinhard * \x3cspan class=\x22hljs-number\x22\x3e255\x3c\/span\x3e);\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e\x3cstrong\x3ePython\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs lsl\x22\x3e# 使用Reinhard色调映射算法获得\x3cspan class=\x22hljs-number\x22\x3e24\x3c\/span\x3e位彩色图像\ntonemapReinhard = cv2.createTonemapReinhard(\x3cspan class=\x22hljs-number\x22\x3e1.5\x3c\/span\x3e, \x3cspan class=\x22hljs-number\x22\x3e0\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e0\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e0\x3c\/span\x3e)\nldrReinhard = tonemapReinhard.process(hdrDebevec)\ncv2.imwrite(\x3cspan class=\x22hljs-string\x22\x3e\x22ldr-Reinhard.jpg\x22\x3c\/span\x3e, ldrReinhard * \x3cspan class=\x22hljs-number\x22\x3e255\x3c\/span\x3e)\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e结果如下：\x3c\/p\x3e\n\x3cp\x3e\x3ca href=\x22http:\/\/www.learnopencv.com\/wp-content\/uploads\/2017\/10\/hdr-Reinhard.jpg\x22\x3e\x3cimg src=\x22https:\/\/p0.ssl.qhimg.com\/t014ee95e5ad48e96b1.jpg\x22 alt=\x22HDR tone mapping using Reinhard\x27s algorithm\x22\x3e\x3c\/a\x3e\x3c\/p\x3e\n\x3cp\x3e\x3cem\x3e使用Reinhard算法的HDR色调映射\x3c\/em\x3e\x3c\/p\x3e\n\x3ch4\x3e\x3ca href=\x22#mantiuk-色调映射\x22\x3e\x3c\/a\x3eMantiuk 色调映射\x3c\/h4\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs lsl\x22\x3ecreateTonemapMantiuk\n(   \n\x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e   gamma = \x3cspan class=\x22hljs-number\x22\x3e1.0\x3c\/span\x3ef,\n\x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e   scale = \x3cspan class=\x22hljs-number\x22\x3e0.7\x3c\/span\x3ef,\n\x3cspan class=\x22hljs-type\x22\x3efloat\x3c\/span\x3e   saturation = \x3cspan class=\x22hljs-number\x22\x3e1.0\x3c\/span\x3ef \n)   \n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e参数 \x3ccode\x3escale\x3c\/code\x3e 是对比度比例因子。 从 0.7 到 0.9 的值通常效果较好\x3c\/p\x3e\n\x3cp\x3e有关更多详细信息，请查看这篇\x3ca href=\x22http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.60.4077\x26amp;rep=rep1\x26amp;type=pdf\x22\x3e论文\x3c\/a\x3e。\x3c\/p\x3e\n\x3cp\x3e\x3cstrong\x3eC\x2b\x2b\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs lsl\x22\x3e\x3cspan class=\x22hljs-comment\x22\x3e\/\/ 使用Mantiuk色调映射算法获得24位彩色图像\x3c\/span\x3e\nMat ldrMantiuk;\nPtr\x26lt;TonemapMantiuk\x26gt; tonemapMantiuk = createTonemapMantiuk(\x3cspan class=\x22hljs-number\x22\x3e2.2\x3c\/span\x3e,\x3cspan class=\x22hljs-number\x22\x3e0.85\x3c\/span\x3e, \x3cspan class=\x22hljs-number\x22\x3e1.2\x3c\/span\x3e);\ntonemapMantiuk-\x26gt;process(hdrDebevec, ldrMantiuk);\nldrMantiuk = \x3cspan class=\x22hljs-number\x22\x3e3\x3c\/span\x3e * ldrMantiuk;\nimwrite(\x3cspan class=\x22hljs-string\x22\x3e\x22ldr-Mantiuk.jpg\x22\x3c\/span\x3e, ldrMantiuk * \x3cspan class=\x22hljs-number\x22\x3e255\x3c\/span\x3e);\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e\x3cstrong\x3ePython\x3c\/strong\x3e\x3c\/p\x3e\n\x3cpre\x3e\x3ccode class=\x22hljs makefile\x22\x3e\x3cspan class=\x22hljs-comment\x22\x3e# 使用Mantiuk色调映射算法获得24位彩色图像\x3c\/span\x3e\ntonemapMantiuk = cv2.createTonemapMantiuk(2.2,0.85, 1.2)\nldrMantiuk = tonemapMantiuk.process(hdrDebevec)\nldrMantiuk = 3 * ldrMantiuk\ncv2.imwrite(\x3cspan class=\x22hljs-string\x22\x3e\x22ldr-Mantiuk.jpg\x22\x3c\/span\x3e, ldrMantiuk * 255)\n\n\x3c\/code\x3e\x3c\/pre\x3e\x3cp\x3e结果如下：\x3c\/p\x3e\n\x3cp\x3e\x3ca href=\x22http:\/\/www.learnopencv.com\/wp-content\/uploads\/2017\/10\/hdr-Mantiuk.jpg\x22\x3e\x3cimg src=\x22https:\/\/p0.ssl.qhimg.com\/t0109e4bcad7ac27665.jpg\x22 alt=\x22HDR tone mapping using Mantiuk\x27s algorithm\x22\x3e\x3c\/a\x3e\x3c\/p\x3e\n\x3cp\x3e\x3cem\x3e使用Mantiuk算法的HDR色调映射\x3c\/em\x3e\x3c\/p\x3e\n\x3ch3\x3e\x3ca href=\x22#订阅然后下载代码\x22\x3e\x3c\/a\x3e订阅然后下载代码\x3c\/h3\x3e\n\x3cp\x3e如果你喜欢这篇文章，并希望下载本文中使用的代码（C\x2b\x2b 和 Python）和示例图片，请\x3ca href=\x22https:\/\/bigvisionllc.leadpages.net\/leadbox\/143948b73f72a2%3A173c9390c346dc\/5649050225344512\/\x22\x3e订阅\x3c\/a\x3e我们的电子杂志。 您还将获得免费的\x3ca href=\x22https:\/\/bigvisionllc.leadpages.net\/leadbox\/143948b73f72a2%3A173c9390c346dc\/5649050225344512\/\x22\x3e计算机视觉资源\x3c\/a\x3e指南。 在我们的电子杂志中，我们分享了用 C\x2b\x2b 还有 Python 编写的 OpenCV 教程和例子，以及计算机视觉和机器学习的算法和新闻。\x3c\/p\x3e\n\x3cp\x3e\x3ca href=\x22https:\/\/bigvisionllc.leadpages.net\/leadbox\/143948b73f72a2%3A173c9390c346dc\/5649050225344512\/\x22\x3e点此订阅\x3c\/a\x3e\x3c\/p\x3e\n\x3cp\x3e图片致谢\x3c\/p\x3e\n\x3cp\x3e本文中使用的四个曝光图像获得 \x3ca href=\x22https:\/\/creativecommons.org\/licenses\/by-sa\/3.0\/\x22\x3eCC BY-SA 3.0\x3c\/a\x3e 许可，并从\x3ca href=\x22https:\/\/en.wikipedia.org\/wiki\/High-dynamic-range_imaging\x22\x3e维基百科的 HDR 页面\x3c\/a\x3e下载。 图像由 Kevin McCoy拍摄。\x3c\/p\x3e\n\x3chr\x3e\n\x3cp\x3e作者简介：\x3c\/p\x3e\n\x3cp\x3e我是一位热爱计算机视觉和机器学习的企业家，拥有十多年的实践经验（还有博士学位）。\x3c\/p\x3e\n\x3cp\x3e2007 年，在完成博士学位之后，我和我的顾问 David Kriegman 博士还有 Kevin Barnes 共同创办了 TAAZ 公司。 我们的计算机视觉和机器学习算法的可扩展性和鲁棒性已经经过了试用了我们产品的超过 1 亿的用户的严格测试。\x3c\/p\x3e\n\x3chr\x3e\n\x3cp\x3evia: \x3ca href=\x22http:\/\/www.learnopencv.com\/high-dynamic-range-hdr-imaging-using-opencv-cpp-python\/\x22\x3ehttp:\/\/www.learnopencv.com\/high-dynamic-range-hdr-imaging-using-opencv-cpp-python\/\x3c\/a\x3e\x3c\/p\x3e\n\x3cp\x3e作者：\x3ca href=\x22http:\/\/www.learnopencv.com\/about\/\x22\x3eSATYA MALLICK\x3c\/a\x3e 译者：\x3ca href=\x22https:\/\/github.com\/Flowsnow\x22\x3eFlowsnow\x3c\/a\x3e 校对：\x3ca href=\x22https:\/\/github.com\/wxy\x22\x3ewxy\x3c\/a\x3e\x3c\/p\x3e\n\x3cp\x3e本文由 \x3ca href=\x22https:\/\/github.com\/LCTT\/TranslateProject\x22\x3eLCTT\x3c\/a\x3e 原创编译，\x3ca href=\x22https:\/\/linux.cn\/\x22\x3eLinux中国\x3c\/a\x3e 荣誉推出\x3c\/p\x3e\n\n          \n"
            html = html.replace(/"{/g, "{")
            html = html.replace(/{"/g, "{")
            html = html.replace(/"}/g, "}")
            html = html.replace(/}"/g, "}")
            $('#raw').html(html);

            let postTitle =  $('.posttitle').text()
            let postContentTitle =  $('#raw > h1').text()
            if(postTitle === postContentTitle){
                $('#raw > h1').hide()
            }
            $('button.preview').hide()
        })</script></div><h1 id="版权声明">版权声明</h1><p>原文链接: <a href="https://www.zcfy.cc/article/high-dynamic-range-imaging-using-opencv-cpp-python">https://www.zcfy.cc/article/high-dynamic-range-imaging-using-opencv-cpp-python</a> 原文标题: 使用 OpenCV 进行高动态范围（HDR）成像 本文仅用于学习、研究和交流目的。转载请注明出处、完整链接以及原作者。</p><p>本文资源来源互联网，仅供学习研究使用，版权归该资源的合法拥有者所有，</p><p>原作者若认为本站侵犯了您的版权，请联系我们，我们会立即删除！</p><h2>本文链接：</h2><a href="https://alili.tech/archive/855c5353/" target="_blank">https://alili.tech/archive/855c5353/</a></div></article><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine/dist/Valine.min.js"></script><div class="blog-post-comments"></div><script>new Valine({
        el: '.blog-post-comments', 
        app_id: 'ItyOVb4I33bTwprf3cY6uqMc-gzGzoHsz', 
        app_key: 'hLhtmd4tT0qJbyO2SgQ8odya', 
        placeholder: '说点什么?', 
        avatar:'robohash',
        notify:true,
        verify:true
    });</script><ul id="more-post-list" class="archive readmore"><h3>其他推荐</h3><li><a href="/archive/hvvo3rmt3dj/">JS打包工具rollup——完全入门指南<aside class="dates">2019-01-04</aside></a></li><li><a href="/archive/semhn25oasq/">Spring Boot [基于Spring Boot 与 Vue的后台脚手架] SanJi Boot Security<aside class="dates">2019-01-04</aside></a></li><li><a href="/archive/t1iml4tjj7r/">WebGL入门demo<aside class="dates">2019-01-04</aside></a></li><li><a href="/archive/8gbs1y0r0ns/">[面试专题]一线互联网大厂面试总结<aside class="dates">2019-01-04</aside></a></li><li><a href="/archive/4os59l0zeel/">react&#43;react-router4&#43;redux最新版构建分享<aside class="dates">2019-01-04</aside></a></li><li><a href="/archive/dznv6a9ewcj/">react虚拟dom机制与diff算法<aside class="dates">2019-01-04</aside></a></li><li><a href="/archive/myiqarfowok/">一套Vue的单页模板：N3-admin<aside class="dates">2019-01-04</aside></a></li><li><a href="/archive/2eeweuxgjbk/">使用 json-server 搭建 api mock 服务 (一)<aside class="dates">2019-01-04</aside></a></li><li><a href="/archive/h7cszygcoqq/">使用Ionic3框架开始第一个混合开发APP<aside class="dates">2019-01-04</aside></a></li><li><a href="/archive/g8by6kv9q8t/">如何只用 CSS 完成漂亮的加载<aside class="dates">2019-01-04</aside></a></li></ul></section></div><footer id="footer"><div class="footer-left">Copyright © 2019 Fan <a href="http://www.miitbeian.gov.cn" rel="external nofollow noopener noreferrer" target="_blank">浙ICP备18045521号</a></div><div class="footer-right"><nav><ul><li><a href="/">Home</a></li><li><a href="/archive/">Archives</a></li><li><a href="/about/">About</a></li><li><a href="http://github.com/Fantasy9527" target="_blank">Github</a></li></ul></nav></div></footer><script src="https://alili.tech/lib/justified-gallery/jquery.justifiedGallery.min.js"></script><script src="https://alili.tech/lib/typed.js"></script><script src="https://alili.tech/js/main.js"></script><script async src=""></script><script>(function(){
  if(location.host!=='alili.tech')return;
  var ga = document.createElement('script');
  var curProtocol = window.location.protocol.split(':')[0];
  ga.src = 'https://www.googletagmanager.com/gtag/js?id=UA-129382678-1';       
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(ga, s);
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-129382678-1');
})()</script><script>(function(){
    if(location.host!=='alili.tech')return;
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script>if ('serviceWorker' in navigator) {
      window.addEventListener('load', () => {
          navigator.serviceWorker
              .register('/sw.js')
              .then(registration => {
                  console.log('SW registered: ', registration);
              })
              .catch(registrationError => {
                  console.log('SW registration failed: ', registrationError);
              });
      });
  }</script></body></html>